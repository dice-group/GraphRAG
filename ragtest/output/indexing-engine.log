00:23:42,567 graphrag.index.cli INFO Logging enabled at D:\Job\7.Dice_WHB\3.Dice_tasks\GraphRAG\ragtest\output\indexing-engine.log
00:23:42,571 graphrag.index.cli INFO Starting pipeline run for: 20241113-002342, dryrun=False
00:23:42,574 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "llama2",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "http://localhost:11434/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "D:\\Job\\7.Dice_WHB\\3.Dice_tasks\\GraphRAG\\ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "D:\\Job\\7.Dice_WHB\\3.Dice_tasks\\GraphRAG\\ragtest\\output",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "D:\\Job\\7.Dice_WHB\\3.Dice_tasks\\GraphRAG\\ragtest\\output",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "tentris",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://tentris-ml.cs.upb.de:8502/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama2",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama2",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama2",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama2",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
00:23:42,587 graphrag.index.create_pipeline_config INFO skipping workflows 
00:23:42,587 graphrag.index.run.run INFO Running pipeline
00:23:42,587 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at D:\Job\7.Dice_WHB\3.Dice_tasks\GraphRAG\ragtest\output
00:23:42,588 graphrag.index.input.load_input INFO loading input from root_dir=input
00:23:42,588 graphrag.index.input.load_input INFO using file storage for input
00:23:42,590 graphrag.index.storage.file_pipeline_storage INFO search D:\Job\7.Dice_WHB\3.Dice_tasks\GraphRAG\ragtest\input for files matching .*\.txt$
00:23:42,591 graphrag.index.input.text INFO found text files from input, found [('book.txt', {})]
00:23:42,594 graphrag.index.input.text INFO Found 1 files, loading 1
00:23:42,599 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'create_final_relationships', 'create_final_text_units', 'create_final_community_reports', 'create_base_documents', 'create_final_documents']
00:23:42,600 graphrag.index.run.run INFO Final # of rows loaded: 1
00:23:42,727 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
00:23:42,733 datashaper.workflow.workflow INFO executing verb orderby
00:23:42,743 datashaper.workflow.workflow INFO executing verb zip
00:23:42,750 datashaper.workflow.workflow INFO executing verb aggregate_override
00:23:42,767 datashaper.workflow.workflow INFO executing verb chunk
00:23:43,54 datashaper.workflow.workflow INFO executing verb select
00:23:43,61 datashaper.workflow.workflow INFO executing verb unroll
00:23:43,71 datashaper.workflow.workflow INFO executing verb rename
00:23:43,76 datashaper.workflow.workflow INFO executing verb genid
00:23:43,88 datashaper.workflow.workflow INFO executing verb unzip
00:23:43,95 datashaper.workflow.workflow INFO executing verb copy
00:23:43,102 datashaper.workflow.workflow INFO executing verb filter
00:23:43,123 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
00:23:43,346 graphrag.index.run.workflow INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
00:23:43,346 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
00:23:43,399 datashaper.workflow.workflow INFO executing verb entity_extract
00:23:43,404 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:11434/v1
00:23:43,417 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for llama2: TPM=0, RPM=0
00:23:43,418 graphrag.index.llm.load_llm INFO create concurrency limiter for llama2: 25
00:23:43,820 datashaper.workflow.workflow INFO executing verb merge_graphs
00:23:43,828 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
00:23:43,986 graphrag.index.run.workflow INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
00:23:43,987 graphrag.utils.storage INFO read table from storage: create_base_extracted_entities.parquet
00:23:44,10 datashaper.workflow.workflow INFO executing verb summarize_descriptions
00:23:44,20 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
00:23:44,180 graphrag.index.run.workflow INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
00:23:44,181 graphrag.utils.storage INFO read table from storage: create_summarized_entities.parquet
00:23:44,211 datashaper.workflow.workflow INFO executing verb cluster_graph
00:23:44,237 datashaper.workflow.workflow INFO executing verb select
00:23:44,240 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
00:23:44,408 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['create_base_entity_graph']
00:23:44,409 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
00:23:44,438 datashaper.workflow.workflow INFO executing verb unpack_graph
00:23:44,451 datashaper.workflow.workflow INFO executing verb rename
00:23:44,470 datashaper.workflow.workflow INFO executing verb select
00:23:44,483 datashaper.workflow.workflow INFO executing verb dedupe
00:23:44,499 datashaper.workflow.workflow INFO executing verb rename
00:23:44,533 datashaper.workflow.workflow INFO executing verb filter
00:23:44,580 datashaper.workflow.workflow INFO executing verb text_split
00:23:44,597 datashaper.workflow.workflow INFO executing verb drop
00:23:44,622 datashaper.workflow.workflow INFO executing verb merge
00:23:44,644 datashaper.workflow.workflow INFO executing verb text_embed
00:23:44,646 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://tentris-ml.cs.upb.de:8502/v1
00:23:44,669 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for tentris: TPM=0, RPM=0
00:23:44,669 graphrag.index.llm.load_llm INFO create concurrency limiter for tentris: 25
00:23:44,671 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 9 inputs via 9 snippets using 1 batches. max_batch_size=16, max_tokens=8191
00:23:45,270 datashaper.workflow.workflow INFO executing verb drop
00:23:45,282 datashaper.workflow.workflow INFO executing verb filter
00:23:45,304 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
00:23:45,509 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['create_base_entity_graph']
00:23:45,510 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
00:23:45,549 datashaper.workflow.workflow INFO executing verb layout_graph
00:23:45,593 datashaper.workflow.workflow INFO executing verb unpack_graph
00:23:45,616 datashaper.workflow.workflow INFO executing verb unpack_graph
00:23:45,646 datashaper.workflow.workflow INFO executing verb drop
00:23:45,670 datashaper.workflow.workflow INFO executing verb filter
00:23:45,714 datashaper.workflow.workflow INFO executing verb select
00:23:45,739 datashaper.workflow.workflow INFO executing verb rename
00:23:45,758 datashaper.workflow.workflow INFO executing verb join
00:23:45,790 datashaper.workflow.workflow INFO executing verb convert
00:23:45,867 datashaper.workflow.workflow INFO executing verb rename
00:23:45,872 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
00:23:46,249 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['create_base_entity_graph']
00:23:46,250 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
00:23:46,295 datashaper.workflow.workflow INFO executing verb create_final_communities
00:23:46,327 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
00:23:46,526 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
00:23:46,526 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
00:23:46,552 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
00:23:46,621 datashaper.workflow.workflow INFO executing verb create_final_relationships_pre_embedding
00:23:46,655 datashaper.workflow.workflow INFO executing verb create_final_relationships_post_embedding
00:23:46,666 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
00:23:46,887 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_final_entities', 'create_final_relationships', 'create_base_text_units']
00:23:46,888 graphrag.utils.storage INFO read table from storage: create_final_entities.parquet
00:23:46,909 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
00:23:46,921 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
00:23:46,974 datashaper.workflow.workflow INFO executing verb create_final_text_units_pre_embedding
00:23:47,19 datashaper.workflow.workflow INFO executing verb select
00:23:47,21 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
00:23:47,230 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
00:23:47,231 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
00:23:47,237 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
00:23:47,279 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
00:23:47,300 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
00:23:47,369 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
00:23:47,403 datashaper.workflow.workflow INFO executing verb prepare_community_reports
00:23:47,403 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 9
00:23:47,455 datashaper.workflow.workflow INFO executing verb create_community_reports
00:26:15,53 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
00:26:15,63 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 147.59400000004098. input_tokens=2104, output_tokens=344
00:26:47,768 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\nYou are an AI assistant that helps a human analyst to perform general information discovery. Information discovery is the process of identifying and assessing relevant information associated with certain entities (e.g., organizations and individuals) within a network.\n\n# Goal\nWrite a comprehensive report of a community, given a list of entities that belong to the community as well as their relationships and optional associated claims. The report will be used to inform decision-makers about information associated with the community and their potential impact. The content of this report includes an overview of the community\'s key entities, their legal compliance, technical capabilities, reputation, and noteworthy claims.\n\n# Report Structure\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community.  IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary":<insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary":<insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\n\n# Example Input\n-----------\nText:\n\nEntities\n\nid,entity,description\n5,VERDANT OASIS PLAZA,Verdant Oasis Plaza is the location of the Unity March\n6,HARMONY ASSEMBLY,Harmony Assembly is an organization that is holding a march at Verdant Oasis Plaza\n\nRelationships\n\nid,source,target,description\n37,VERDANT OASIS PLAZA,UNITY MARCH,Verdant Oasis Plaza is the location of the Unity March\n38,VERDANT OASIS PLAZA,HARMONY ASSEMBLY,Harmony Assembly is holding a march at Verdant Oasis Plaza\n39,VERDANT OASIS PLAZA,UNITY MARCH,The Unity March is taking place at Verdant Oasis Plaza\n40,VERDANT OASIS PLAZA,TRIBUNE SPOTLIGHT,Tribune Spotlight is reporting on the Unity march taking place at Verdant Oasis Plaza\n41,VERDANT OASIS PLAZA,BAILEY ASADI,Bailey Asadi is speaking at Verdant Oasis Plaza about the march\n43,HARMONY ASSEMBLY,UNITY MARCH,Harmony Assembly is organizing the Unity March\n\nOutput:\n{{\n    "title": "Verdant Oasis Plaza and Unity March",\n    "summary": "The community revolves around the Verdant Oasis Plaza, which is the location of the Unity March. The plaza has relationships with the Harmony Assembly, Unity March, and Tribune Spotlight, all of which are associated with the march event.",\n    "rating": 5.0,\n    "rating_explanation": "The impact severity rating is moderate due to the potential for unrest or conflict during the Unity March.",\n    "findings": [\n        {{\n            "summary": "Verdant Oasis Plaza as the central location",\n            "explanation": "Verdant Oasis Plaza is the central entity in this community, serving as the location for the Unity March. This plaza is the common link between all other entities, suggesting its significance in the community. The plaza\'s association with the march could potentially lead to issues such as public disorder or conflict, depending on the nature of the march and the reactions it provokes. [Data: Entities (5), Relationships (37, 38, 39, 40, 41,+more)]"\n        }},\n        {{\n            "summary": "Harmony Assembly\'s role in the community",\n            "explanation": "Harmony Assembly is another key entity in this community, being the organizer of the march at Verdant Oasis Plaza. The nature of Harmony Assembly and its march could be a potential source of threat, depending on their objectives and the reactions they provoke. The relationship between Harmony Assembly and the plaza is crucial in understanding the dynamics of this community. [Data: Entities(6), Relationships (38, 43)]"\n        }},\n        {{\n            "summary": "Unity March as a significant event",\n            "explanation": "The Unity March is a significant event taking place at Verdant Oasis Plaza. This event is a key factor in the community\'s dynamics and could be a potential source of threat, depending on the nature of the march and the reactions it provokes. The relationship between the march and the plaza is crucial in understanding the dynamics of this community. [Data: Relationships (39)]"\n        }},\n        {{\n            "summary": "Role of Tribune Spotlight",\n            "explanation": "Tribune Spotlight is reporting on the Unity March taking place in Verdant Oasis Plaza. This suggests that the event has attracted media attention, which could amplify its impact on the community. The role of Tribune Spotlight could be significant in shaping public perception of the event and the entities involved. [Data: Relationships (40)]"\n        }}\n    ]\n}}\n\n\n# Real Data\n\nUse the following text for your answer. Do not make anything up in your answer.\n\nText:\n-----Entities-----\nhuman_readable_id,title,description,degree\r\n1,DICE RESEARCH,Organization affiliated with Simon Bin,3\r\n3,JENNY SMITH,,2\r\n4,KENNETH WONG,,1\r\n8,PROJECT Y,,1\r\n\n\n-----Relationships-----\nhuman_readable_id,source,target,description,rank\r\n0,SIMON BIN,DICE RESEARCH,Simon Bin was affiliated with DICE Research,8\r\n5,DICE RESEARCH,JENNY SMITH,Jenny Smith is affiliated with DICE Research,5\r\n6,DICE RESEARCH,KENNETH WONG,Kenneth Wong is affiliated with DICE Research,4\r\n7,JENNY SMITH,PROJECT Y,Jenny Smith was involved in Project Y at DICE Research,3\r\n\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community.  IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary":<insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary":<insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\nOutput:'}
00:29:49,380 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\nYou are an AI assistant that helps a human analyst to perform general information discovery. Information discovery is the process of identifying and assessing relevant information associated with certain entities (e.g., organizations and individuals) within a network.\n\n# Goal\nWrite a comprehensive report of a community, given a list of entities that belong to the community as well as their relationships and optional associated claims. The report will be used to inform decision-makers about information associated with the community and their potential impact. The content of this report includes an overview of the community\'s key entities, their legal compliance, technical capabilities, reputation, and noteworthy claims.\n\n# Report Structure\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community.  IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary":<insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary":<insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\n\n# Example Input\n-----------\nText:\n\nEntities\n\nid,entity,description\n5,VERDANT OASIS PLAZA,Verdant Oasis Plaza is the location of the Unity March\n6,HARMONY ASSEMBLY,Harmony Assembly is an organization that is holding a march at Verdant Oasis Plaza\n\nRelationships\n\nid,source,target,description\n37,VERDANT OASIS PLAZA,UNITY MARCH,Verdant Oasis Plaza is the location of the Unity March\n38,VERDANT OASIS PLAZA,HARMONY ASSEMBLY,Harmony Assembly is holding a march at Verdant Oasis Plaza\n39,VERDANT OASIS PLAZA,UNITY MARCH,The Unity March is taking place at Verdant Oasis Plaza\n40,VERDANT OASIS PLAZA,TRIBUNE SPOTLIGHT,Tribune Spotlight is reporting on the Unity march taking place at Verdant Oasis Plaza\n41,VERDANT OASIS PLAZA,BAILEY ASADI,Bailey Asadi is speaking at Verdant Oasis Plaza about the march\n43,HARMONY ASSEMBLY,UNITY MARCH,Harmony Assembly is organizing the Unity March\n\nOutput:\n{{\n    "title": "Verdant Oasis Plaza and Unity March",\n    "summary": "The community revolves around the Verdant Oasis Plaza, which is the location of the Unity March. The plaza has relationships with the Harmony Assembly, Unity March, and Tribune Spotlight, all of which are associated with the march event.",\n    "rating": 5.0,\n    "rating_explanation": "The impact severity rating is moderate due to the potential for unrest or conflict during the Unity March.",\n    "findings": [\n        {{\n            "summary": "Verdant Oasis Plaza as the central location",\n            "explanation": "Verdant Oasis Plaza is the central entity in this community, serving as the location for the Unity March. This plaza is the common link between all other entities, suggesting its significance in the community. The plaza\'s association with the march could potentially lead to issues such as public disorder or conflict, depending on the nature of the march and the reactions it provokes. [Data: Entities (5), Relationships (37, 38, 39, 40, 41,+more)]"\n        }},\n        {{\n            "summary": "Harmony Assembly\'s role in the community",\n            "explanation": "Harmony Assembly is another key entity in this community, being the organizer of the march at Verdant Oasis Plaza. The nature of Harmony Assembly and its march could be a potential source of threat, depending on their objectives and the reactions they provoke. The relationship between Harmony Assembly and the plaza is crucial in understanding the dynamics of this community. [Data: Entities(6), Relationships (38, 43)]"\n        }},\n        {{\n            "summary": "Unity March as a significant event",\n            "explanation": "The Unity March is a significant event taking place at Verdant Oasis Plaza. This event is a key factor in the community\'s dynamics and could be a potential source of threat, depending on the nature of the march and the reactions it provokes. The relationship between the march and the plaza is crucial in understanding the dynamics of this community. [Data: Relationships (39)]"\n        }},\n        {{\n            "summary": "Role of Tribune Spotlight",\n            "explanation": "Tribune Spotlight is reporting on the Unity March taking place in Verdant Oasis Plaza. This suggests that the event has attracted media attention, which could amplify its impact on the community. The role of Tribune Spotlight could be significant in shaping public perception of the event and the entities involved. [Data: Relationships (40)]"\n        }}\n    ]\n}}\n\n\n# Real Data\n\nUse the following text for your answer. Do not make anything up in your answer.\n\nText:\n-----Entities-----\nhuman_readable_id,title,description,degree\r\n1,DICE RESEARCH,Organization affiliated with Simon Bin,3\r\n3,JENNY SMITH,,2\r\n4,KENNETH WONG,,1\r\n8,PROJECT Y,,1\r\n\n\n-----Relationships-----\nhuman_readable_id,source,target,description,rank\r\n0,SIMON BIN,DICE RESEARCH,Simon Bin was affiliated with DICE Research,8\r\n5,DICE RESEARCH,JENNY SMITH,Jenny Smith is affiliated with DICE Research,5\r\n6,DICE RESEARCH,KENNETH WONG,Kenneth Wong is affiliated with DICE Research,4\r\n7,JENNY SMITH,PROJECT Y,Jenny Smith was involved in Project Y at DICE Research,3\r\n\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community.  IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary":<insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary":<insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\nOutput:'}
00:32:03,547 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
00:32:03,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 2 retries took 131.23400000005495. input_tokens=2066, output_tokens=300
00:32:03,691 datashaper.workflow.workflow INFO executing verb window
00:32:03,724 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
00:32:03,973 graphrag.index.run.workflow INFO dependencies for create_base_documents: ['create_final_text_units']
00:32:03,974 graphrag.utils.storage INFO read table from storage: create_final_text_units.parquet
00:32:04,64 datashaper.workflow.workflow INFO executing verb unroll
00:32:04,92 datashaper.workflow.workflow INFO executing verb select
00:32:04,122 datashaper.workflow.workflow INFO executing verb rename
00:32:04,162 datashaper.workflow.workflow INFO executing verb join
00:32:04,215 datashaper.workflow.workflow INFO executing verb aggregate_override
00:32:04,260 datashaper.workflow.workflow INFO executing verb join
00:32:04,294 datashaper.workflow.workflow INFO executing verb rename
00:32:04,322 datashaper.workflow.workflow INFO executing verb convert
00:32:04,356 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
00:32:04,647 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_documents']
00:32:04,647 graphrag.utils.storage INFO read table from storage: create_base_documents.parquet
00:32:04,719 datashaper.workflow.workflow INFO executing verb rename
00:32:04,722 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
00:32:04,876 graphrag.index.cli INFO All workflows completed successfully.
00:57:27,210 graphrag.index.cli INFO Logging enabled at D:\Job\7.Dice_WHB\3.Dice_tasks\GraphRAG\ragtest\output\indexing-engine.log
00:57:27,225 graphrag.index.cli INFO Starting pipeline run for: 20241113-005727, dryrun=False
00:57:27,230 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "llama2",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "http://localhost:11434/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "D:\\Job\\7.Dice_WHB\\3.Dice_tasks\\GraphRAG\\ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "D:\\Job\\7.Dice_WHB\\3.Dice_tasks\\GraphRAG\\ragtest\\output",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "D:\\Job\\7.Dice_WHB\\3.Dice_tasks\\GraphRAG\\ragtest\\output",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "tentris",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://tentris-ml.cs.upb.de:8502/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama2",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama2",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama2",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "llama2",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
00:57:27,235 graphrag.index.create_pipeline_config INFO skipping workflows 
00:57:27,235 graphrag.index.run.run INFO Running pipeline
00:57:27,235 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at D:\Job\7.Dice_WHB\3.Dice_tasks\GraphRAG\ragtest\output
00:57:27,235 graphrag.index.input.load_input INFO loading input from root_dir=input
00:57:27,235 graphrag.index.input.load_input INFO using file storage for input
00:57:27,238 graphrag.index.storage.file_pipeline_storage INFO search D:\Job\7.Dice_WHB\3.Dice_tasks\GraphRAG\ragtest\input for files matching .*\.txt$
00:57:27,238 graphrag.index.input.text INFO found text files from input, found [('book.txt', {})]
00:57:27,248 graphrag.index.input.text INFO Found 1 files, loading 1
00:57:27,255 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'create_final_relationships', 'create_final_text_units', 'create_final_community_reports', 'create_base_documents', 'create_final_documents']
00:57:27,255 graphrag.index.run.run INFO Final # of rows loaded: 1
00:57:27,418 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
00:57:27,426 datashaper.workflow.workflow INFO executing verb orderby
00:57:27,434 datashaper.workflow.workflow INFO executing verb zip
00:57:27,446 datashaper.workflow.workflow INFO executing verb aggregate_override
00:57:27,461 datashaper.workflow.workflow INFO executing verb chunk
00:57:27,793 datashaper.workflow.workflow INFO executing verb select
00:57:27,793 datashaper.workflow.workflow INFO executing verb unroll
00:57:27,818 datashaper.workflow.workflow INFO executing verb rename
00:57:27,826 datashaper.workflow.workflow INFO executing verb genid
00:57:27,835 datashaper.workflow.workflow INFO executing verb unzip
00:57:27,844 datashaper.workflow.workflow INFO executing verb copy
00:57:27,851 datashaper.workflow.workflow INFO executing verb filter
00:57:27,878 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
00:57:28,106 graphrag.index.run.workflow INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
00:57:28,106 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
00:57:28,155 datashaper.workflow.workflow INFO executing verb entity_extract
00:57:28,252 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:11434/v1
00:57:28,276 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for llama2: TPM=0, RPM=0
00:57:28,276 graphrag.index.llm.load_llm INFO create concurrency limiter for llama2: 25
00:59:44,227 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
00:59:44,239 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 135.96799999999348. input_tokens=1822, output_tokens=215
01:01:25,683 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
01:01:25,683 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 101.43800000008196. input_tokens=34, output_tokens=259
01:01:25,973 datashaper.workflow.workflow INFO executing verb merge_graphs
01:01:25,987 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
01:01:26,218 graphrag.index.run.workflow INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
01:01:26,218 graphrag.utils.storage INFO read table from storage: create_base_extracted_entities.parquet
01:01:26,448 datashaper.workflow.workflow INFO executing verb summarize_descriptions
01:01:26,456 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
01:01:26,684 graphrag.index.run.workflow INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
01:01:26,684 graphrag.utils.storage INFO read table from storage: create_summarized_entities.parquet
01:01:26,748 datashaper.workflow.workflow INFO executing verb cluster_graph
01:01:26,862 datashaper.workflow.workflow INFO executing verb select
01:01:26,873 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
01:01:27,83 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['create_base_entity_graph']
01:01:27,91 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
01:01:27,131 datashaper.workflow.workflow INFO executing verb unpack_graph
01:01:27,164 datashaper.workflow.workflow INFO executing verb rename
01:01:27,188 datashaper.workflow.workflow INFO executing verb select
01:01:27,204 datashaper.workflow.workflow INFO executing verb dedupe
01:01:27,238 datashaper.workflow.workflow INFO executing verb rename
01:01:27,272 datashaper.workflow.workflow INFO executing verb filter
01:01:27,354 datashaper.workflow.workflow INFO executing verb text_split
01:01:27,388 datashaper.workflow.workflow INFO executing verb drop
01:01:27,420 datashaper.workflow.workflow INFO executing verb merge
01:01:27,452 datashaper.workflow.workflow INFO executing verb text_embed
01:01:27,465 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://tentris-ml.cs.upb.de:8502/v1
01:01:27,482 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for tentris: TPM=0, RPM=0
01:01:27,485 graphrag.index.llm.load_llm INFO create concurrency limiter for tentris: 25
01:01:27,485 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 3 inputs via 3 snippets using 1 batches. max_batch_size=16, max_tokens=8191
01:01:27,535 httpx INFO HTTP Request: POST http://tentris-ml.cs.upb.de:8502/v1/embeddings "HTTP/1.1 200 OK"
01:01:27,551 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.06300000008195639. input_tokens=37, output_tokens=0
01:01:27,714 datashaper.workflow.workflow INFO executing verb drop
01:01:27,765 datashaper.workflow.workflow INFO executing verb filter
01:01:27,795 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
01:01:28,51 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['create_base_entity_graph']
01:01:28,51 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
01:01:28,125 datashaper.workflow.workflow INFO executing verb layout_graph
01:01:28,166 datashaper.workflow.workflow INFO executing verb unpack_graph
01:01:28,190 datashaper.workflow.workflow INFO executing verb unpack_graph
01:01:28,223 datashaper.workflow.workflow INFO executing verb filter
01:01:28,288 datashaper.workflow.workflow INFO executing verb drop
01:01:28,322 datashaper.workflow.workflow INFO executing verb select
01:01:28,347 datashaper.workflow.workflow INFO executing verb rename
01:01:28,386 datashaper.workflow.workflow INFO executing verb convert
01:01:28,543 datashaper.workflow.workflow INFO executing verb join
01:01:28,592 datashaper.workflow.workflow INFO executing verb rename
01:01:28,601 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
01:01:28,870 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['create_base_entity_graph']
01:01:28,880 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
01:01:28,944 datashaper.workflow.workflow INFO executing verb create_final_communities
01:01:28,983 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
01:01:29,240 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
01:01:29,240 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
01:01:29,261 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
01:01:29,314 datashaper.workflow.workflow INFO executing verb create_final_relationships_pre_embedding
01:01:29,357 datashaper.workflow.workflow INFO executing verb create_final_relationships_post_embedding
01:01:29,379 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
01:01:29,673 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_final_relationships', 'create_final_entities', 'create_base_text_units']
01:01:29,673 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
01:01:29,695 graphrag.utils.storage INFO read table from storage: create_final_entities.parquet
01:01:29,706 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
01:01:29,821 datashaper.workflow.workflow INFO executing verb create_final_text_units_pre_embedding
01:01:29,969 datashaper.workflow.workflow INFO executing verb select
01:01:29,973 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
01:01:30,206 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
01:01:30,248 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
01:01:30,255 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
01:01:30,356 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
01:01:30,411 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
01:01:30,444 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
01:01:30,476 datashaper.workflow.workflow INFO executing verb prepare_community_reports
01:01:30,476 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 3
01:01:30,552 datashaper.workflow.workflow INFO executing verb create_community_reports
01:04:25,863 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
01:04:25,866 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 175.28099999995902. input_tokens=1972, output_tokens=308
01:04:26,19 datashaper.workflow.workflow INFO executing verb window
01:04:26,19 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
01:04:26,387 graphrag.index.run.workflow INFO dependencies for create_base_documents: ['create_final_text_units']
01:04:26,387 graphrag.utils.storage INFO read table from storage: create_final_text_units.parquet
01:04:26,493 datashaper.workflow.workflow INFO executing verb unroll
01:04:26,552 datashaper.workflow.workflow INFO executing verb select
01:04:26,601 datashaper.workflow.workflow INFO executing verb rename
01:04:26,656 datashaper.workflow.workflow INFO executing verb join
01:04:26,721 datashaper.workflow.workflow INFO executing verb aggregate_override
01:04:26,758 datashaper.workflow.workflow INFO executing verb join
01:04:26,802 datashaper.workflow.workflow INFO executing verb rename
01:04:26,891 datashaper.workflow.workflow INFO executing verb convert
01:04:27,14 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
01:04:27,292 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_documents']
01:04:27,292 graphrag.utils.storage INFO read table from storage: create_base_documents.parquet
01:04:27,374 datashaper.workflow.workflow INFO executing verb rename
01:04:27,374 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
01:04:27,544 graphrag.index.cli INFO All workflows completed successfully.
